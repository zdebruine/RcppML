% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nmf_methods.R, R/predict_nmf.r
\docType{methods}
\name{subset,nmf-method}
\alias{subset,nmf-method}
\alias{[,nmf,ANY,ANY,ANY-method}
\alias{head,nmf-method}
\alias{show,nmf-method}
\alias{dimnames,nmf-method}
\alias{dim,nmf-method}
\alias{t,nmf-method}
\alias{sort,nmf-method}
\alias{prod,nmf-method}
\alias{$,nmf-method}
\alias{coerce,nmf,list-method}
\alias{[[,nmf-method}
\alias{predict,nmf-method}
\title{nmf class methods}
\usage{
\S4method{subset}{nmf}(x, i, ...)

\S4method{[}{nmf,ANY,ANY,ANY}(x, i)

\S4method{head}{nmf}(x, n = getOption("digits"), ...)

\S4method{show}{nmf}(object)

\S4method{dimnames}{nmf}(x)

\S4method{dim}{nmf}(x)

\S4method{t}{nmf}(x)

\S4method{sort}{nmf}(x, decreasing = TRUE, ...)

\S4method{prod}{nmf}(x, ..., na.rm = FALSE)

\S4method{$}{nmf}(x, name)

\S4method{coerce}{nmf,list}(from, to)

\S4method{[[}{nmf}(x, i)

\S4method{predict}{nmf}(object, data, L1 = 0, L2 = 0, mask = NULL, ...)
}
\arguments{
\item{x}{object of class \code{nmf}.}

\item{i}{indices}

\item{...}{arguments passed to or from other methods}

\item{n}{number of rows/columns to show}

\item{object}{fitted model, class \code{nmf}, generally the result of calling \code{nmf}, with models of equal dimensions as \code{data}}

\item{decreasing}{logical. Should the sort be increasing or decreasing?}

\item{na.rm}{remove na values}

\item{name}{name of nmf class slot}

\item{from}{class which the coerce method should perform coercion from}

\item{to}{class which the coerce method should perform coercion to}

\item{data}{dense or sparse matrix of features in rows and samples in columns. Prefer \code{matrix} or \code{Matrix::dgCMatrix}, respectively}

\item{L1}{a single LASSO penalty in the range (0, 1]}

\item{L2}{a single Ridge penalty greater than zero}

\item{mask}{dense or sparse matrix of values in \code{data} to handle as missing. Prefer \code{Matrix::dgCMatrix}. Alternatively, specify "\code{zeros}" or "\code{NA}" to mask either all zeros or NA values.}
}
\value{
object of class \code{\link{nmf}}
}
\description{
Given an NMF model in the form \eqn{A = wdh}, \code{project} projects \code{w} onto \code{A} to solve for \code{h}.
}
\details{
TO DO: add documentation
For the alternating least squares matrix factorization update problem \eqn{A = wh}, the updates 
(or projection) of \eqn{h} is given by the equation: \deqn{w^Twh = wA_j} 
which is in the form \eqn{ax = b} where \eqn{a = w^Tw} \eqn{x = h} and \eqn{b = wA_j} for all columns \eqn{j} in \eqn{A}.

Any L1 penalty is subtracted from \eqn{b} and should generally be scaled to \code{max(b)}, where \eqn{b = WA_j} for all columns \eqn{j} in \eqn{A}. An easy way to properly scale an L1 penalty is to normalize all columns in \eqn{w} to sum to the same value (e.g. 1). No scaling is applied in this function. Such scaling guarantees that \code{L1 = 1} gives a completely sparse solution.

There are specializations for dense and sparse input matrices, symmetric input matrices, and for rank-1 and rank-2 projections. See documentation for \code{\link{nmf}} for theoretical details and guidance.
}
\examples{
\dontrun{
w <- matrix(runif(1000 * 10), 1000, 10)
h_true <- matrix(runif(10 * 100), 10, 100)
# A is the crossproduct of "w" and "h" with 10\% signal dropout
A <- (w \%*\% h_true) * (r_sparsematrix(1000, 100, 10) > 0)
h <- project(w, A)
cor(as.vector(h_true), as.vector(h))

# alternating projections refine solution (like NMF)
mse_bad <- mse(w, rep(1, ncol(w)), h, A) # mse before alternating updates
h <- project(w, A)
w <- t(project(h, t(A)))
h <- project(w, A)
w <- t(project(h, t(A)))
h <- project(w, A)
w <- t(project(h, t(A)))
mse_better <- mse(w, rep(1, ncol(w)), h, A) # mse after alternating updates
mse_better < mse_bad
}
}
\references{
DeBruine, ZJ, Melcher, K, and Triche, TJ. (2021). "High-performance non-negative matrix factorization for large single-cell data." BioRXiv.
}
\seealso{
\code{\link{nnls}}, \code{\link{nmf}}
}
\author{
Zach DeBruine
}
